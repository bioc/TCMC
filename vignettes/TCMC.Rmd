---
title: "Introduction to TCMC"
author: 
  - name: Dany Mukesha
    affiliation:
    - Université Côte d'Azur
    email: danymukesha@gmail.com
abstract: 
    Machine learning model selection is a critical step in the development 
    of predictive analytics projects. We introduce TCMC, an R package made 
    to streamline the process of comparing and selecting classification models.
    TCMC facilitates the evaluation of 13 diverse classification algorithms 
    using the caret package, providing users with a clean framework for model
    assessment.
    
    TCMC implements a powerful methodology, including repeated cross-validation
    for performance estimation and the generation of variable importance plots. 
    The package supports customizable training/test split ratios and produces 
    confusion matrices for detailed model evaluation. The primary metric of 
    TCMC for comparison is accuracy, but it also enables the calculation of 
    additional metrics such as sensitivity, specificity, and F1 score.
    
    We demonstrate the utility of package using the Pima Indians Diabetes 
    dataset, comparing models such as Learning Vector Quantization (LVQ), 
    Gradient Boosting Machine (GBM), Support Vector Machine (SVM), and 
    Random Forest (RF), more others. The results showcase the ability of 
    package to efficiently train multiple models and provide clear comparisons
    of their performance.
    
    TCMC addresses the need for a standardized, reproducible approach to model
    selection in classification tasks. By automating the comparison process 
    and providing detailed performance metrics, it enables the user to make 
    informed decisions about model selection, potentially improving the overall 
    quality of predictive models in various domains.
    
    This tool contributes to the field of machine learning by offering 
    a user-friendly, extensible platform for model comparison, suitable 
    for both research and practical applications in data science and 
    predictive analytics.
output: 
  BiocStyle::html_document:
    self_contained: yes
    toc: true
    toc_float: true
    toc_depth: 2
    code_folding: show
date: "`r doc_date()`"
package: "`r pkg_ver('TCMC')`"
vignette: >
  %\VignetteIndexEntry{Introduction to TCMC}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", crop = NULL)
```

```{r vignetteSetup, echo=FALSE, message=FALSE, warning = FALSE}
startTime <- Sys.time()
library("RefManageR")
bib <- c(
    R = citation(),
    BiocStyle = citation("BiocStyle")[1],
    SummarizedExperiment = citation("SummarizedExperiment")[1],
    knitr = citation("knitr")[1],
    RefManageR = citation("RefManageR")[1],
    rmarkdown = citation("rmarkdown")[1],
    sessioninfo = citation("sessioninfo")[1],
    testthat = citation("testthat")[1],
    mlbench = citation("mlbench")[1],
    TCMC = citation("TCMC")[1]
)
```

# Basics

## Install `TCMC`

`r Biocpkg("TCMC")` package `r Citep(bib[["TCMC"]])` will be soon available 
on [Bioconductor](http://bioconductor.org).

```{r "install", eval = FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE)) {
    install.packages("BiocManager")
}
BiocManager::install("TCMC")
BiocManager::valid()
```

## Citing `TCMC`

I hope that `r Biocpkg("TCMC")` will be useful for research. Please use
the following information to cite the package and the overall approach. 
Thank you!

```{r "citation"}
citation("TCMC")
```

# Quick start to using `TCMC`

```{r "start", message=FALSE, warning=FALSE}
library(TCMC)
library(mlbench)
```

```{r data}
data(PimaIndiansDiabetes)
str(PimaIndiansDiabetes)
```

```{r model, message=FALSE, warning=FALSE}
# for this example only LVQ and GBM are being tested
results <- model_comparer(PimaIndiansDiabetes, "diabetes", for_utest = TRUE)
```

```{r plot_vip}
# plot variable importance for a specific model
plot_importance(results$trained_models$lvq, "LVQ")
plot_importance(results$trained_models$rf, "RF")
```

```{r assess}
# access trained models
models_results <- resamples(results$trained_models)
summary(models_results)
```

```{r plot_acc}
bwplot(models_results)
```

```{r best_model}
best_model <- results$performance$rf
best_model
```

# Example with `SummarizedExperiment`

Example integrated with 
`r Biocpkg("SummarizedExperiment")` `r Citep(bib[["SummarizedExperiment"]])` 
with machine learning workflows for evaluating treatment effectiveness.

-   ***Scenario description***: In this example, we investigate 
the effectiveness of different treatments in influencing positive outcomes
for a simulated clinical dataset. Each treatment corresponds to a class 
of drugs (e.g., TZD and DPP-4), and the outcome variable indicates whether 
the response to treatment was positive or negative. Using the 
`r Biocpkg("SummarizedExperiment")` `r Citep(bib[["SummarizedExperiment"]])` 
class from Bioconductor, we will preprocess the data, train machine learning
models, and analyze the most impactful features and models.

-   ***Data simulation***: The dataset contains measurements of sugar levels
across eight samples, along with metadata describing treatment classes 
and outcomes. The 
`r Biocpkg("SummarizedExperiment")` `r Citep(bib[["SummarizedExperiment"]])` 
object is used to organize and manage this data.

```{r initial_class, warning=FALSE, message=FALSE}
library(SummarizedExperiment)

# Simulate data
nrows <- 200 # Number of features (e.g., genes or biomarkers)
ncols <- 8  # Number of samples
sugar_level <- matrix(runif(nrows * ncols, 1, 500), nrows)

# Metadata: treatment classes and outcomes
colData <- DataFrame(Treatment_class = rep(c("TZD", "DPP-4"), 4),
        row.names = LETTERS[1:8])
Outcome <- DataFrame(Outcome = (rep(c("neg", "pos"), 5)))
se0 <- SummarizedExperiment(assays = SimpleList(counts = sugar_level),
        colData = colData, metadata = Outcome)
```

```{r formatting}
# in the case the input is a SummarizedExperiment, extract assay and metadata
if (inherits(se0, "SummarizedExperiment")) {
    data <- as.data.frame(assay(se0))
    metadata <- as.data.frame(metadata(se0))
    data_df <- cbind(metadata, data)
}
feature_names <- c("Outcome",
    "TreatmentA", "TreatmentB", "TreatmentC", "TreatmentD", 
    "TreatmentE", "TreatmentF", "TreatmentG", "TreatmentH"
)
colnames(data_df) <- feature_names
data_df$Outcome <- data_df$Outcome |> as.factor()
str(data_df) 

```

```{r results_outcome, warning=FALSE}
results <- model_comparer(data = data_df, "Outcome", for_utest = TRUE)
```

```{r plot_vis_outcome}
plot_importance(results$trained_models$lvq, "LVQ")
plot_importance(results$trained_models$rf, "RF")

models_results <- resamples(results$trained_models)
summary(models_results)

bwplot(models_results)

best_model <- results$performance$rf
best_model
```

By identifying the most predictive treatments and features, 
we can inform clinical decision-making and prioritize interventions 
that maximize positive outcomes.

Here is an example of you can cite your package inside the vignette:

-   `r Biocpkg("TCMC")` `r Citep(bib[["TCMC"]])`

The data set utilized in the example is originally from the National 
Institute of Diabetes and Digestive and Kidney Diseases.

-   Source: `r CRANpkg("mlbench")` `r Citep(bib[["mlbench"]])`

Date the vignette was generated.

```{r reproduce1, echo=FALSE}
Sys.time()
```

Wallclock time spent generating the vignette.

```{r reproduce2, echo=FALSE}
totalTime <- diff(c(startTime, Sys.time()))
round(totalTime, digits = 3)
```

`R` session information.

```{r reproduce3, echo=FALSE}
library("sessioninfo")
options(width = 120)
session_info()
```

# Bibliography

```{r vignetteBiblio, results = "asis", echo = FALSE, warning = FALSE}
PrintBibliography(bib, .opts = list(hyperlink = "to.doc", style = "html"))
```
